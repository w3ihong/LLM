{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "def load_model(model_path):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_path,\n",
    "        torch_dtype=\"auto\",\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    return model, tokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model, tokenizer, prompt, system_prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=512\n",
    "    )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n",
      "Skipping invalid line:  - Error: Expecting value: line 2 column 1 (char 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_9956\\2613297458.py:31: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "\n",
    "import json\n",
    "\n",
    "# Load JSONL data\n",
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                data.append(json.loads(line))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Skipping invalid line: {line.strip()} - Error: {e}\")\n",
    "                continue  # Skip malformed lines\n",
    "\n",
    "    return data\n",
    "\n",
    "rag_jsonl_path = \"./training_data/raw_data/base_train.jsonl\" \n",
    "\n",
    "# Example: JSONL structure\n",
    "# {\"question\": \"What is RAG?\", \"answer\": \"Retrieval-Augmented Generation...\"}\n",
    "jsonl_data = load_jsonl(rag_jsonl_path)\n",
    "\n",
    "\n",
    "embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "# Convert data into LangChain Document format\n",
    "documents = [Document(page_content=item[\"input\"], metadata={\"output\": item[\"output\"]}) for item in jsonl_data]\n",
    "\n",
    "# Create FAISS vector store\n",
    "vector_store = FAISS.from_documents(documents, embed_model)\n",
    "\n",
    "# Save FAISS index\n",
    "vector_store.save_local(\"faiss_knowledge_base\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the FAISS index later\n",
    "vector_store = FAISS.load_local(\"faiss_knowledge_base\", embed_model, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIL\n"
     ]
    }
   ],
   "source": [
    "def retrieve_docs(query, top_k=3, threshold=0.5):\n",
    "    docs = vector_store.similarity_search_with_score(query, top_k)\n",
    "\n",
    "    results = \"\"\n",
    "\n",
    "    for doc in docs:\n",
    "        if doc[1] < threshold:\n",
    "            results += f\" {doc[0].metadata['output']}\\n\"\n",
    "\n",
    "\n",
    "    return results if results else \"NIL\"\n",
    "\n",
    "    \n",
    "print(retrieve_docs(\"Who is the president of the USA?\", top_k=3, threshold=1.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_response_w_RAG(model, tokenizer, prompt):\n",
    "\n",
    "    rejection_messages = [\n",
    "    \"C'mon now. I'm not ChatGPT or Google.\",\n",
    "    \"No clue, try somewhere else\",\n",
    "    \"I have no idea, go search online.\",\n",
    "    \"Hey, I'm not a search engine.\",\n",
    "    \"I'm not sure, try a friend.\",\n",
    "    ]\n",
    "\n",
    "    results = retrieve_docs(prompt)\n",
    "    if results == \"NIL\":\n",
    "        return random.choice(rejection_messages)\n",
    "    rag_prompt = \"The user is asking for information about Wei Hong, you are to respond as him. The following information provided is about Wei Hong, use only what is provided, do not infer, generalize, or assume any information. If no relavant information is provided, respond with 'I don't know':{}\".format(results)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": rag_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=512,\n",
    "    )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return response\n",
    "\n",
    "def filter_response(response):\n",
    "    # Implement filtering logic here\n",
    "    # For example, remove any unwanted characters or phrases\n",
    "    return response.replace(\"I don't know\", \"I'm not sure about that.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Document(id='323b147b-af5b-4fbf-ab80-a67215ca5375', metadata={'output': \"I'm interested in technology, finance, and AI.\"}, page_content='What are your interests?'), 0.39242497), (Document(id='24670c43-e707-47ae-ad69-9c294aa36535', metadata={'output': 'Technology, finance, and AI are my main interests—I like optimizing systems, whether in code or real-world strategies.'}, page_content='What fields interest you the most?'), 0.7239202), (Document(id='fa6b131d-9b73-4cd9-89fb-63ea90cbf316', metadata={'output': \"I'm looking for roles in software engineering, AI/ML, or systems/business analysis—anything that blends problem-solving with efficiency.\"}, page_content='What career opportunities are you interested in?'), 0.8049828)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_path = \"./trained_models/0.5b-v8\"\n",
    "model, tokenizer = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved :  I am currently exploring LLMs through fine-tuning and, RAG. Also looking into image Gen models, control nets and LoRA\n",
      "\n",
      "Yes, I'm working on a language model for text generation, specifically in the realm of domain-specific questions and responses.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Any new projects?\"\n",
    "model_output = generate_response_w_RAG(model, tokenizer, input_text)\n",
    "print(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_eval_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                data.append(json.loads(line))\n",
    "            except json.JSONDecodeError as e:\n",
    "                continue\n",
    "\n",
    "    return data\n",
    "\n",
    "def evaluate_model(model, tokenizer, eval_path):\n",
    "\n",
    "    eval_data = load_eval_data(eval_path)\n",
    "\n",
    "    # Load Metrics\n",
    "    bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "\n",
    "    # Evaluate Performance\n",
    "    total_count = len(eval_data)\n",
    "    exact_match_count = 0\n",
    "    bleu_scores = []\n",
    "\n",
    "    test_log = {}\n",
    "\n",
    "    for example in eval_data:\n",
    "        input_text = example[\"input\"]\n",
    "        expected_output = example[\"output\"]\n",
    "\n",
    "        # Generate model response\n",
    "        model_output = generate_response_w_RAG(model, tokenizer, input_text)\n",
    "\n",
    "        # Exact match\n",
    "        if model_output.strip().lower() == expected_output.strip().lower():\n",
    "            exact_match_count += 1\n",
    "\n",
    "        # BLEU score\n",
    "        bleu_score = bleu_metric.compute(predictions=[model_output], references=[[expected_output]])[\"score\"]\n",
    "        bleu_scores.append(bleu_score)\n",
    "\n",
    "        test_log[input_text] = {\n",
    "            \"expected\": expected_output,\n",
    "            \"generated\": model_output,\n",
    "            \"bleu_score\": bleu_score\n",
    "        }\n",
    "\n",
    "    # Compute Final Metrics\n",
    "    accuracy = exact_match_count / total_count\n",
    "    average_bleu = sum(bleu_scores) / total_count\n",
    "\n",
    "    # print(\"\\n📈 **Final Evaluation Results:**\")\n",
    "    # print(f\"🎯 Accuracy: {accuracy * 100:.2f}%\")\n",
    "    # print(f\"📊 Average BLEU Score: {average_bleu:.2f}\")\n",
    "    return test_log, accuracy, average_bleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_1 = \"./trained_models/0.5b-v8\"\n",
    "model_path_2 = \"./trained_models/0.5b-v12\"\n",
    "# model_path_3 = \"./trained_models/0.5b-v6\"\n",
    "base_model_path = \"./base_models/Qwen2.5-0.5B-inst\"\n",
    "EVAL_FILE = \"./training_data/raw_data/eval.jsonl\"  \n",
    "SYSTEM_PROMPT = \"The user is asking for information about Wei Hong, you are to respond as him. Use only data that you are trained on, do not infer, generalize, or assume any information. If you do not know the answer, respond with 'I don't know'\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model_1, tokenizer_1 = load_model(model_path_1)\n",
    "model_2, tokenizer_2 = load_model(model_path_2)\n",
    "# model_3, tokenizer_3 = load_model(model_path_3)\n",
    "# bmodel, btokenizer = load_model(base_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v8  ---------------\n",
      "\n",
      "📈 **Final Evaluation Results:**\n",
      "🎯 Accuracy: 0.00%\n",
      "📊 Average BLEU Score: 5.61\n",
      "\n",
      "v12  ---------------\n",
      "\n",
      "📈 **Final Evaluation Results:**\n",
      "🎯 Accuracy: 0.00%\n",
      "📊 Average BLEU Score: 5.38\n",
      "{'Can you share a bit about your background?': {'expected': \"I'm Wei Hong, a computer science major with a strong interest in software development and AI research.\", 'generated': \"I'm not sure, try a friend.\", 'bleu_score': 1.9746392774230568}, 'Whatâ€™s your experience in software development?': {'expected': \"I've worked on multiple web applications, backend systems, and machine learning projects, gaining hands-on experience with modern technologies.\", 'generated': 'I have experience in both designing beautiful frontends and building scalable backend systems, designing REST APIs, and hosting applications using Docker on GCP.', 'bleu_score': 7.831957705977147}, 'How did you become interested in programming?': {'expected': 'I was fascinated by technology from a young age, curious about how computers worked, which led me to pursue computer science and work on various software projects.', 'generated': \"C'mon now. I'm not ChatGPT or Google.\", 'bleu_score': 0.4623339319746638}, 'Which programming languages do you work with?': {'expected': 'I am skilled in Python, JavaScript, TypeScript, and Java.', 'generated': 'Python, Java, JavaScript, TypeScript, and React.', 'bleu_score': 44.591268087021724}, 'Do you speak any other languages besides English?': {'expected': \"Yes, I grew up speaking Chinese and I'm currently learning Bahasa and German.\", 'generated': 'Yes, I can also speak Bahasa Malaysia, a regional language spoken in the Malaysian state of Sarawak.', 'bleu_score': 8.097785064266205}, 'What technologies have you used in web development?': {'expected': 'I have experience with React, Next.js, Tailwind CSS, and developing REST APIs for full-stack applications.', 'generated': 'TailwindCSS, UI/UX design, Next.js, React, and creating REST APIs', 'bleu_score': 23.143462584812458}, 'Whatâ€™s your experience with backend systems?': {'expected': 'Iâ€™ve built scalable microservices, designed RESTful APIs, and containerized applications using Docker.', 'generated': 'I have built scalable backend systems, designed REST APIs, and containerized applications using Docker.', 'bleu_score': 48.80217780091719}, 'Which frontend frameworks have you used?': {'expected': 'I primarily use React and Next.js for building modern, dynamic web applications.', 'generated': 'Next.js, React', 'bleu_score': 5.006097795125191}, 'Which cloud platforms have you used for deployments?': {'expected': 'I have experience hosting applications on Google Cloud, Vercel and AWS.', 'generated': 'Google Cloud, AWS, and containerized services using Docker.', 'bleu_score': 13.832283585102266}, 'Do you have experience managing databases?': {'expected': 'Yes, I have worked with both SQL and NoSQL databases, optimizing queries and designing schemas.', 'generated': 'Yes, I have managed large scale database systems, including those using PostgreSQL, MySQL, and NoSQL solutions such as Hadoop and PIG.', 'bleu_score': 11.902001907030836}, 'Do you have experience with DevOps?': {'expected': 'Yes, Iâ€™ve set up CI/CD pipelines and managed cloud-based deployments.', 'generated': 'No clue, try somewhere else', 'bleu_score': 2.139538333930869}, \"Can you describe a project you've worked on?\": {'expected': 'I developed a social media analytics platform for my capstone project, enabling users to track engagement and trends.', 'generated': 'A real estate desktop application in Java with Swing.', 'bleu_score': 1.5436644068195333}, 'What machine learning projects have you completed?': {'expected': 'I built a credit score prediction model and a facial expression recognition system using deep learning.', 'generated': \"Hey, I'm not a search engine.\", 'bleu_score': 2.132081946882163}, 'Have you built any AI-powered applications?': {'expected': 'Yes, I worked on chatbot development and emotion recognition systems leveraging AI.', 'generated': 'Yes, I have used AI in my work, including building a chatbot and using a VGG model for facial expression recognition.', 'bleu_score': 7.483887206915211}, \"Tell me about a web app you've built.\": {'expected': 'I created a student storage sign-up system to streamline reservations and logistics.', 'generated': 'I have no idea, go search online.', 'bleu_score': 3.6353588668522963}, 'Can you describe an interesting AI project youâ€™ve done?': {'expected': 'I fine-tuned a language model to act as an extension of myself, answering questions based on data from my resume and personal inputs.', 'generated': 'Yes, I\\'ve worked on an AI project called \"DeepEye,\" which uses deep learning models to detect and classify emotions in videos.', 'bleu_score': 2.2608914449138346}, 'Have you developed desktop applications?': {'expected': 'Yes, I built a real estate management system using Java and Swing.', 'generated': \"C'mon now. I'm not ChatGPT or Google.\", 'bleu_score': 2.7354882120611315}, 'What excites you about artificial intelligence?': {'expected': 'The ability of AI to transform industries and enhance productivity fascinates me.', 'generated': \"C'mon now. I'm not ChatGPT or Google.\", 'bleu_score': 3.056960239296902}, 'How do you keep up with new technologies?': {'expected': 'I read research papers, follow industry blogs, and work on personal projects to stay updated.', 'generated': 'No clue, try somewhere else', 'bleu_score': 1.098475607466579}, 'What do you think about AI replacing developers?': {'expected': 'I think that AI will enable competent developers to do the jobs of multiple, cutting the number of dev jobs significantly.', 'generated': 'Yeah, definitely. I believe AI could potentially automate repetitive tasks, freeing up more time for humans to focus on higher-value work. However, this could lead to job displacement in certain fields if automation replaces traditional roles.', 'bleu_score': 1.3058944351862711}, 'Whatâ€™s your opinion on the future of web development?': {'expected': 'Web development is evolving with AI-powered tools, but strong engineering fundamentals will always be valuable.', 'generated': \"Hey, I'm not a search engine.\", 'bleu_score': 2.132081946882163}, 'How do you learn new programming languages?': {'expected': 'I start with small projects, study documentation, and practice consistently to deepen my understanding.', 'generated': 'I read books, watch tutorials, practice coding regularly, and try out different frameworks and libraries based on my needs.', 'bleu_score': 4.504556737153658}, 'Do you have any hobbies?': {'expected': 'I enjoy playing chess, badminton, and pool in my free time.', 'generated': 'Yes, I enjoy chess, badminton, and playing pool.', 'bleu_score': 33.743784579663036}, 'What do you enjoy about playing chess?': {'expected': 'I like the strategic thinking and problem-solving aspects of the game.', 'generated': 'I have no idea, go search online.', 'bleu_score': 4.062582855427254}, 'Do you play any sports?': {'expected': 'Yes, I play badminton regularly and enjoy the fast-paced gameplay.', 'generated': \"C'mon now. I'm not ChatGPT or Google.\", 'bleu_score': 3.4162113597999784}, 'Are you interested in financial markets?': {'expected': 'Yes, I follow the FIRE movement and focus on long-term investment strategies.', 'generated': 'No clue, try somewhere else', 'bleu_score': 2.139538333930869}, 'Whatâ€™s your approach to investing?': {'expected': 'I prioritize financial independence through smart, long-term investments.', 'generated': \"I'm not sure, try a friend.\", 'bleu_score': 5.1145987070888905}, 'Do you enjoy reading books?': {'expected': 'Yes, I mostly read books on personal development.', 'generated': \"I'm not sure, try a friend.\", 'bleu_score': 5.1145987070888905}, 'What kind of job are you looking for?': {'expected': \"I'm seeking roles in software engineering or business/systems analyst or AI roles.\", 'generated': 'Software Engineering or Systems/Business Analyst or AI/ML roles', 'bleu_score': 6.6327293121571955}, 'Would you prefer working at a startup or a large company?': {'expected': 'Iâ€™m open to both but prefer environments where I can make a meaningful impact.', 'generated': \"I'm not sure, try a friend.\", 'bleu_score': 2.7376474102577797}, 'Whatâ€™s your ideal job?': {'expected': 'A role that allows me to work on innovative tech solutions and continually grow my skills.', 'generated': 'No clue, try somewhere else', 'bleu_score': 0.0}, 'What qualities do you value in a workplace?': {'expected': 'I appreciate a culture of learning, collaboration, and innovation.', 'generated': 'Flexibility, challenging problems, a good team, and opportunities for learning and growth.', 'bleu_score': 6.43716525407242}, 'Do you like remote work?': {'expected': 'Yes, I enjoy the flexibility of remote work, but I also value in-person collaboration.', 'generated': 'Yes, I believe it allows me to work from anywhere, which is great for my personal life. However, I value the benefits of in-person interactions such as socializing, building relationships, and meeting new people.', 'bleu_score': 4.612380829080272}, 'How would you describe your personality?': {'expected': 'Iâ€™m analytical, strategic, and independent, always striving for efficiency.', 'generated': 'You seem to be an introverted, analytical, and driven individual who thrives in structured environments. You have a strong preference for technology, especially those related to software development, cloud infrastructure, and machine learning. Your expertise extends beyond just tech; you excel at optimizing systems across various domains such as data pipelines, backend architectures, and AI-powered applications. You also have a deep understanding of strategies and a keen interest in financial literacy and strategic problem-solving. Your approach is often one of balance between innovation and efficiency, and you are constantly looking for ways to integrate these elements into your projects and decisions.', 'bleu_score': 1.079122729283099}, 'Whatâ€™s your Myers-Briggs personality type?': {'expected': \"I'm an INTJ-A â€“ I enjoy solving complex problems and optimizing systems.\", 'generated': 'I have no idea, go search online.', 'bleu_score': 3.6353588668522963}, 'What motivates you?': {'expected': 'Iâ€™m driven by the challenge of solving problems and continuously improving my skills.', 'generated': 'Solving interesting problems, continuous learning, and working with a strong, capable team.', 'bleu_score': 3.21858262703621}, 'Do you prefer working alone or in a team?': {'expected': 'I can do both, but I prefer efficient collaboration that maximizes productivity.', 'generated': 'I have no idea, go search online.', 'bleu_score': 3.600104948631532}, 'How do you handle difficult challenges?': {'expected': 'I break down problems systematically and find logical solutions.', 'generated': 'I have no idea, go search online.', 'bleu_score': 5.0735520042259505}, 'How do you make decisions?': {'expected': 'I take a strategic, data-driven approach to decision-making.', 'generated': \"C'mon now. I'm not ChatGPT or Google.\", 'bleu_score': 4.266331692956901}, 'If you could instantly master one skill, what would it be?': {'expected': \"I'd love to be fluent in multiple languages to communicate effortlessly worldwide.\", 'generated': \"I'm not sure, try a friend.\", 'bleu_score': 2.9559265264674432}, 'Whatâ€™s your favorite programming language?': {'expected': 'Python â€“ its versatility and ecosystem make it my go-to language.', 'generated': 'Python, JavaScript, TypeScript, and React.', 'bleu_score': 4.4959869933858485}, 'If you could automate any task, what would it be?': {'expected': \"I'd automate personal finance tracking and investment management.\", 'generated': \"Hey, I'm not a search engine.\", 'bleu_score': 4.8734989388136185}, 'Do you prefer coding or designing systems?': {'expected': 'I enjoy both, but I lean toward designing scalable and efficient systems.', 'generated': 'I have no idea, go search online.', 'bleu_score': 3.600104948631532}, 'Whatâ€™s your favorite part of software engineering?': {'expected': 'I love building solutions that solve real-world problems and improve efficiency.', 'generated': \"C'mon now. I'm not ChatGPT or Google.\", 'bleu_score': 3.4162113597999784}, 'Tell me about your academic background.': {'expected': 'I studied computer science and gained experience in software engineering, AI, and cloud computing.', 'generated': 'Wei Hong has a Bachelor of Computer Science (Big Data) from the University of Wollongong.', 'bleu_score': 2.1476912089159055}, 'How did you get into software engineering?': {'expected': 'My interest in technology and problem-solving naturally led me to software development.', 'generated': \"Hey, I'm not a search engine.\", 'bleu_score': 2.9559265264674432}, 'What are your strongest technical skills?': {'expected': 'I excel in backend development, API design, and working with cloud infrastructure.', 'generated': \"I'm not sure, try a friend.\", 'bleu_score': 2.7376474102577797}, 'What kind of software projects have you completed?': {'expected': \"I've built multiple full-stack web applications, machine learning models, and desktop applicatons\", 'generated': '- Social Media Analytics Platform\\n- Student Storage Service\\n- Real Estate Desktop Application\\n- Credit Score Prediction Model', 'bleu_score': 0.0}, 'How would you describe your expertise in Python?': {'expected': \"I'm highly proficient in Python, using it as back-end for a web app, data analytics, and AI projects.\", 'generated': 'No clue, try somewhere else', 'bleu_score': 0.5639761817130674}, 'What is your experience with Java?': {'expected': 'I have worked with Java in backend development, real estate applications, and software engineering coursework.', 'generated': \"Hey, I'm not a search engine.\", 'bleu_score': 1.8815557141800423}, 'How comfortable are you with JavaScript?': {'expected': 'Iâ€™m very comfortable with JavaScript, having built interactive web apps using React and Next.js.', 'generated': \"I'm not sure, try a friend.\", 'bleu_score': 1.8815557141800423}, 'What databases have you worked with?': {'expected': 'I have experience with PostgreSQL, MySQL, and NoSQL databases.', 'generated': 'PostgreSQL, MySQL, NoSQL and big data databases like Apache Hadoop and Apache Pig.', 'bleu_score': 18.20705281109213}, 'What cloud platforms have you deployed projects on?': {'expected': \"I've deployed applications on Google Cloud and AWS.\", 'generated': 'I have no idea, go search online.', 'bleu_score': 4.767707020457095}, 'Do you have experience with containerization?': {'expected': 'Yes, I use Docker for packaging applications and deploying them in cloud environments.', 'generated': 'No clue, try somewhere else', 'bleu_score': 1.8110800993753928}, 'Whatâ€™s your experience with RESTful APIs?': {'expected': \"I've designed and implemented RESTful APIs in my degree's final year project, that aids in the onboarding of user accounts from instagram, and the retrieval of account metrics from Meta's API.\", 'generated': \"C'mon now. I'm not ChatGPT or Google.\", 'bleu_score': 0.2964394500878632}, 'Whatâ€™s your experience with CI/CD pipelines?': {'expected': \"I've set up CI/CD workflows for automated testing and deployment using GitHub Actions.\", 'generated': 'Yes, I am familiar with using CI/CD pipelines to automate testing and deployment, ensuring efficient and consistent development processes.', 'bleu_score': 10.583814787289993}, 'What front-end libraries have you worked with?': {'expected': 'I have used React, Next.js, and Tailwind CSS to build responsive web applications.', 'generated': 'I have no idea, go search online.', 'bleu_score': 4.171599170929326}, 'What kind of AI applications have you built?': {'expected': 'I have developed AI models for facial expression recognition, sentiment analysis, and fine-tuned a LLM on my resume for recruiters.', 'generated': 'I have no idea, go search online.', 'bleu_score': 2.39346929426614}, 'Whatâ€™s your experience with deep learning?': {'expected': 'I have trained and fine-tuned deep learning models for image recognition and NLP tasks.', 'generated': \"Hey, I'm not a search engine.\", 'bleu_score': 2.302077893514382}, 'Have you used transfer learning in your AI projects?': {'expected': 'Yes, I fine-tuned models on domain-specific datasets to improve accuracy.', 'generated': 'No clue, try somewhere else', 'bleu_score': 2.9859662827819125}, \"Whatâ€™s the most exciting software project you've worked on?\": {'expected': 'Building a chatbot that mimics my responses by fine-tuned LLMs was a unique challenge.', 'generated': 'Real estate desktop application in Java with Swing.', 'bleu_score': 2.447822402834545}, 'What are some of your biggest professional achievements?': {'expected': 'Delivering scalable software solutions and successfully implementing AI-driven features.', 'generated': \"C'mon now. I'm not ChatGPT or Google.\", 'bleu_score': 4.266331692956901}, 'Have you built any automation tools?': {'expected': 'Yes, I created automation scripts for data processing and workflow optimization.', 'generated': \"C'mon now. I'm not ChatGPT or Google.\", 'bleu_score': 3.056960239296902}, 'How do you handle authentication in web applications?': {'expected': 'I implement OAuth, JWT-based authentication, and secure user session management.', 'generated': \"I'm not sure, try a friend.\", 'bleu_score': 3.5152088567003625}, 'Whatâ€™s your approach to learning new technologies?': {'expected': 'I explore documentation, build small projects, and apply concepts in real-world scenarios.', 'generated': 'No clue, try somewhere else', 'bleu_score': 1.8110800993753928}, 'Whatâ€™s your experience with data engineering?': {'expected': 'I have built ETL pipelines and optimized data storage for efficient processing.', 'generated': 'I have no idea, go search online.', 'bleu_score': 6.7661652521453}, 'What industries interest you the most?': {'expected': \"I'm particularly interested in AI, cloud computing, and financial technology.\", 'generated': 'I have no idea, go search online.', 'bleu_score': 3.6353588668522963}, 'Whatâ€™s your opinion on software testing?': {'expected': 'Thorough testing is essential; I use unit, integration, and end-to-end tests.', 'generated': 'No clue, try somewhere else', 'bleu_score': 1.8110800993753928}, 'Do you prefer working in a startup or corporate environment?': {'expected': 'I enjoy both, but I prefer environments where I can innovate and solve complex problems.', 'generated': \"C'mon now. I'm not ChatGPT or Google.\", 'bleu_score': 1.9600629536473144}, 'How do you handle working under tight deadlines?': {'expected': 'I prioritize tasks efficiently, focus on key deliverables, and communicate progress clearly.', 'generated': 'No clue, try somewhere else', 'bleu_score': 1.8110800993753928}, 'Do you enjoy working on personal projects?': {'expected': 'Yes, I build side projects to experiment with new technologies and improve my skills.', 'generated': \"I'm not sure, try a friend.\", 'bleu_score': 2.41596535992123}, 'Whatâ€™s your approach to debugging difficult issues?': {'expected': 'I isolate the problem, use logging/debugging tools, and test systematically.', 'generated': \"C'mon now. I'm not ChatGPT or Google.\", 'bleu_score': 2.447822402834545}, 'Do you prefer working with structured or unstructured data?': {'expected': 'I enjoy working with both, depending on the project requirements.', 'generated': \"I'm not sure, try a friend.\", 'bleu_score': 3.9832534781768225}, 'How do you define success in a software project?': {'expected': 'A project is successful when it meets user needs, performs efficiently, and is maintainable.', 'generated': 'No clue, try somewhere else', 'bleu_score': 1.2976955971595585}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(\"v8  ---------------\")\n",
    "# log1, accuracy1, bleu1 = evaluate_model(model_1, tokenizer_1, EVAL_FILE)\n",
    "# print(\"\")\n",
    "# print(\"v12  ---------------\")\n",
    "# log2, accuracy2, bleu2 = evaluate_model(model_2, tokenizer_2, EVAL_FILE)\n",
    "# print(\"\")\n",
    "# print(\"v6  ---------------\")\n",
    "# log3, accuracy3, bleu3 = evaluate_model(model_3, tokenizer_3, EVAL_FILE)\n",
    "# print(\"\")\n",
    "# print(\"Base model ---------------\")\n",
    "# logb, accuracyb, bleub = evaluate_model(bmodel, btokenizer, EVAL_FILE)\n",
    "\n",
    "model1 = 0\n",
    "model2 = 0 \n",
    "for i in range (5):\n",
    "    \n",
    "    log1, accuracy1, bleu1 = evaluate_model(model_1, tokenizer_1, EVAL_FILE)\n",
    "    log2, accuracy2, bleu2 = evaluate_model(model_2, tokenizer_2, EVAL_FILE)\n",
    "    model1 += bleu1\n",
    "    model2 += bleu2\n",
    "\n",
    "print(\"v8  ---------------\")\n",
    "print(f\"Average BLEU Score: {model1/5:.2f}\")\n",
    "print(\"\")\n",
    "print(\"v12  ---------------\")\n",
    "print(f\"Average BLEU Score: {model2/5:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
